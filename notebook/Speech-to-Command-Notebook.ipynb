{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Speech-to-Command-Notebook.ipynb","provenance":[],"authorship_tag":"ABX9TyPjrPQdwQuO7z/+y1vvHgLY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rw2G6-tOShyx"},"source":["Get the code and dataset from github"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsJqO0dzNvAh","executionInfo":{"status":"ok","timestamp":1623939388442,"user_tz":-120,"elapsed":3938,"user":{"displayName":"Aurélien MARCHAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijsbBTtHpqSNAl0r_zm6SmIuZHehvfoMtGz08m=s64","userId":"06972844859717762232"}},"outputId":"3dee9f29-d12a-4c3a-f799-a2ed6623628b"},"source":["%cd /content/\n","!git clone https://github.com/AurelienMarchal/Speech-to-Command.git\n","%cd Speech-to-Command/\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content\n","Cloning into 'Speech-to-Command'...\n","remote: Enumerating objects: 578, done.\u001b[K\n","remote: Counting objects: 100% (578/578), done.\u001b[K\n","remote: Compressing objects: 100% (575/575), done.\u001b[K\n","remote: Total 578 (delta 9), reused 565 (delta 2), pack-reused 0\u001b[K\n","Receiving objects: 100% (578/578), 32.00 MiB | 23.49 MiB/s, done.\n","Resolving deltas: 100% (9/9), done.\n","/content/Speech-to-Command\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CDzYgkk1SX3o"},"source":["Library installation (this takes a while)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"WNepN8axaCcz","executionInfo":{"status":"ok","timestamp":1623941029920,"user_tz":-120,"elapsed":355281,"user":{"displayName":"Aurélien MARCHAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijsbBTtHpqSNAl0r_zm6SmIuZHehvfoMtGz08m=s64","userId":"06972844859717762232"}},"outputId":"515b433b-bbce-4904-c90f-07b2db12b738"},"source":["!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install speechbrain\n","!pip install transformers"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.0+cu111\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n","\u001b[K     |█████████████▌                  | 834.1MB 1.3MB/s eta 0:14:11tcmalloc: large alloc 1147494400 bytes == 0x563d08aa8000 @  0x7f0fe05ea615 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd02347f0 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd03353e1 0x563cd02956a9 0x563cd0200cc4 0x563cd01c1559 0x563cd02354f8 0x563cd01c230a 0x563cd02303b5 0x563cd022f7ad 0x563cd01c23ea 0x563cd02303b5 0x563cd01c230a 0x563cd02303b5\n","\u001b[K     |█████████████████               | 1055.7MB 1.4MB/s eta 0:11:16tcmalloc: large alloc 1434370048 bytes == 0x563d4d0fe000 @  0x7f0fe05ea615 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd02347f0 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd03353e1 0x563cd02956a9 0x563cd0200cc4 0x563cd01c1559 0x563cd02354f8 0x563cd01c230a 0x563cd02303b5 0x563cd022f7ad 0x563cd01c23ea 0x563cd02303b5 0x563cd01c230a 0x563cd02303b5\n","\u001b[K     |█████████████████████▋          | 1336.2MB 1.3MB/s eta 0:08:32tcmalloc: large alloc 1792966656 bytes == 0x563cd1f30000 @  0x7f0fe05ea615 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd02347f0 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd03353e1 0x563cd02956a9 0x563cd0200cc4 0x563cd01c1559 0x563cd02354f8 0x563cd01c230a 0x563cd02303b5 0x563cd022f7ad 0x563cd01c23ea 0x563cd02303b5 0x563cd01c230a 0x563cd02303b5\n","\u001b[K     |███████████████████████████▎    | 1691.1MB 1.4MB/s eta 0:03:22tcmalloc: large alloc 2241208320 bytes == 0x563d3cd18000 @  0x7f0fe05ea615 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd02347f0 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd0230853 0x563cd02b2e36 0x563cd03353e1 0x563cd02956a9 0x563cd0200cc4 0x563cd01c1559 0x563cd02354f8 0x563cd01c230a 0x563cd02303b5 0x563cd022f7ad 0x563cd01c23ea 0x563cd02303b5 0x563cd01c230a 0x563cd02303b5\n","\u001b[K     |████████████████████████████████| 1982.2MB 1.2MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x563dc267a000 @  0x7f0fe05e91e7 0x563cd01f3f37 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd01c230a 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd022f4ae\n","tcmalloc: large alloc 2477817856 bytes == 0x563eacda2000 @  0x7f0fe05ea615 0x563cd01bdcdc 0x563cd029d52a 0x563cd01c0afd 0x563cd02b1fed 0x563cd0234988 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023060e 0x563cd01c230a 0x563cd023060e 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd022f4ae 0x563cd01c23ea 0x563cd023132a 0x563cd022f4ae 0x563cd01c2a81\n","\u001b[K     |████████████████████████████████| 1982.2MB 3.9kB/s \n","\u001b[?25hCollecting torchvision==0.9.0+cu111\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n","\u001b[K     |████████████████████████████████| 17.6MB 191kB/s \n","\u001b[?25hCollecting torchaudio==0.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/9a/4e2e6dbde627ffb8a6d1d4ebc4683edecad1c08099969f1d7760d92175ff/torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n","Installing collected packages: torch, torchvision, torchaudio\n","  Found existing installation: torchvision 0.9.1+cu101\n","    Uninstalling torchvision-0.9.1+cu101:\n","      Successfully uninstalled torchvision-0.9.1+cu101\n","  Found existing installation: torchaudio 0.9.0\n","    Uninstalling torchaudio-0.9.0:\n","      Successfully uninstalled torchaudio-0.9.0\n","Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fxUOTvcybmAb","executionInfo":{"status":"ok","timestamp":1623941082832,"user_tz":-120,"elapsed":942,"user":{"displayName":"Aurélien MARCHAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijsbBTtHpqSNAl0r_zm6SmIuZHehvfoMtGz08m=s64","userId":"06972844859717762232"}},"outputId":"5f8613b1-15c7-4841-88b4-6f795ff0a3a3"},"source":["import torch\n","# This should print Tesla T4\n","torch.cuda.get_device_name(0)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"G3tZX41HU87L"},"source":["Start training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JkNc4fl1P7kF","executionInfo":{"status":"ok","timestamp":1623941936812,"user_tz":-120,"elapsed":832391,"user":{"displayName":"Aurélien MARCHAL","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GijsbBTtHpqSNAl0r_zm6SmIuZHehvfoMtGz08m=s64","userId":"06972844859717762232"}},"outputId":"d7cf75b4-7a7a-47a0-c2e9-8bbd61ee16fc"},"source":["!python train.py hparams/hparam.yaml"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/Speech-to-Command\n","2021-06-17 14:45:09.162929: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Some weights of the model checkpoint at facebook/wav2vec2-large-lv60 were not used when initializing Wav2Vec2Model: ['project_q.bias', 'quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.weight', 'project_hid.weight', 'quantizer.codevectors']\n","- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","speechbrain.core - Beginning experiment!\n","speechbrain.core - Experiment folder: results/wav2vec_DNN/1234\n","prepare - Starting dataset preparation.\n","prepare - Going through k_fold : 0\n","prepare - Going through k_fold : 1\n","prepare - Going through k_fold : 2\n","prepare - Going through k_fold : 3\n","prepare - Going through k_fold : 4\n","prepare - Preparation finished.\n","speechbrain.dataio.encoder - Load called, but CategoricalEncoder is not empty. Loaded data will overwrite everything. This is normal if there is e.g. an unk label defined at init.\n","speechbrain.core - Info: auto_mix_prec arg overridden by command line input\n","speechbrain.core - 315.5M trainable parameters in Speech2CommandBrain\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n","speechbrain.utils.epoch_loop - Going into epoch 1\n","100% 203/203 [02:16<00:00,  1.49it/s, train_loss=4.73]\n","100% 68/68 [00:18<00:00,  3.59it/s]\n","speechbrain.utils.train_logger - epoch: 1, lr: 3.00e-04 - train loss: 4.73 - valid loss: 4.78, valid ErrorRate: 9.91e-01\n","speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-48-47+00\n","speechbrain.utils.epoch_loop - Going into epoch 2\n","100% 203/203 [02:23<00:00,  1.42it/s, train_loss=4.7]\n","100% 68/68 [00:18<00:00,  3.59it/s]\n","speechbrain.nnet.schedulers - Changing lr from 0.0003 to 0.00024\n","speechbrain.utils.train_logger - epoch: 2, lr: 3.00e-04 - train loss: 4.70 - valid loss: 4.81, valid ErrorRate: 9.91e-01\n","speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-51-34+00\n","speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-48-47+00\n","speechbrain.utils.epoch_loop - Going into epoch 3\n","100% 203/203 [02:22<00:00,  1.42it/s, train_loss=4.69]\n","100% 68/68 [00:18<00:00,  3.58it/s]\n","speechbrain.nnet.schedulers - Changing lr from 0.00024 to 0.00019\n","speechbrain.utils.train_logger - epoch: 3, lr: 2.40e-04 - train loss: 4.69 - valid loss: 4.76, valid ErrorRate: 9.89e-01\n","speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-54-20+00\n","speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-51-34+00\n","speechbrain.utils.epoch_loop - Going into epoch 4\n","100% 203/203 [02:22<00:00,  1.42it/s, train_loss=4.68]\n","100% 68/68 [00:18<00:00,  3.58it/s]\n","speechbrain.nnet.schedulers - Changing lr from 0.00019 to 0.00015\n","speechbrain.utils.train_logger - epoch: 4, lr: 1.92e-04 - train loss: 4.68 - valid loss: 4.74, valid ErrorRate: 9.89e-01\n","speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-57-06+00\n","speechbrain.utils.checkpoints - Deleted checkpoint in results/wav2vec_DNN/1234/save/CKPT+2021-06-17+14-54-20+00\n","speechbrain.utils.epoch_loop - Going into epoch 5\n"," 79% 160/203 [01:43<00:27,  1.55it/s, train_loss=4.68]\n","speechbrain.core - Exception:\n","Traceback (most recent call last):\n","  File \"train.py\", line 260, in <module>\n","    valid_loader_kwargs=hparams[\"valid_dataloader_opts\"],\n","  File \"/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\", line 1022, in fit\n","    loss = self.fit_batch(batch)\n","  File \"/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\", line 851, in fit_batch\n","    if self.check_gradients(loss):\n","  File \"/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\", line 896, in check_gradients\n","    (p for p in self.modules.parameters()), self.max_grad_norm\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 40, in clip_grad_norm_\n","    p.grad.detach().mul_(clip_coef.to(p.grad.device))\n","KeyboardInterrupt\n"],"name":"stdout"}]}]}